{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jainab khatri.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUWEy0wdcYy3"
      },
      "source": [
        "In [7]:\n",
        "import numpy as np # Imports Numpy\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "In [8]:\n",
        "from sklearn.datasets import load_boston   # Imports Boston dataset\n",
        "df = load_boston()\n",
        "In [10]:\n",
        "df.keys()  #Returns all the keys of the data set ditionary\n",
        "Out[10]:\n",
        "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])\n",
        "In [11]:\n",
        "print(df.DESCR)  # Info about Dataset (Description)\n",
        ".. _boston_dataset:\n",
        "\n",
        "Boston house prices dataset\n",
        "---------------------------\n",
        "\n",
        "**Data Set Characteristics:**  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        ".. topic:: References\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "\n",
        "In [15]:\n",
        "boston = pd.DataFrame(df.data, columns=df.feature_names)   # Converts into more schematic data\n",
        "boston.head()\n",
        "Out[15]:\n",
        "CRIM\tZN\tINDUS\tCHAS\tNOX\tRM\tAGE\tDIS\tRAD\tTAX\tPTRATIO\tB\tLSTAT\n",
        "0\t0.00632\t18.0\t2.31\t0.0\t0.538\t6.575\t65.2\t4.0900\t1.0\t296.0\t15.3\t396.90\t4.98\n",
        "1\t0.02731\t0.0\t7.07\t0.0\t0.469\t6.421\t78.9\t4.9671\t2.0\t242.0\t17.8\t396.90\t9.14\n",
        "2\t0.02729\t0.0\t7.07\t0.0\t0.469\t7.185\t61.1\t4.9671\t2.0\t242.0\t17.8\t392.83\t4.03\n",
        "3\t0.03237\t0.0\t2.18\t0.0\t0.458\t6.998\t45.8\t6.0622\t3.0\t222.0\t18.7\t394.63\t2.94\n",
        "4\t0.06905\t0.0\t2.18\t0.0\t0.458\t7.147\t54.2\t6.0622\t3.0\t222.0\t18.7\t396.90\t5.33\n",
        "In [16]:\n",
        "boston[\"TARGET\"] = df.target     # Adds New Column i.e, our target\n",
        "boston.head()\n",
        "Out[16]:\n",
        "CRIM\tZN\tINDUS\tCHAS\tNOX\tRM\tAGE\tDIS\tRAD\tTAX\tPTRATIO\tB\tLSTAT\tTARGET\n",
        "0\t0.00632\t18.0\t2.31\t0.0\t0.538\t6.575\t65.2\t4.0900\t1.0\t296.0\t15.3\t396.90\t4.98\t24.0\n",
        "1\t0.02731\t0.0\t7.07\t0.0\t0.469\t6.421\t78.9\t4.9671\t2.0\t242.0\t17.8\t396.90\t9.14\t21.6\n",
        "2\t0.02729\t0.0\t7.07\t0.0\t0.469\t7.185\t61.1\t4.9671\t2.0\t242.0\t17.8\t392.83\t4.03\t34.7\n",
        "3\t0.03237\t0.0\t2.18\t0.0\t0.458\t6.998\t45.8\t6.0622\t3.0\t222.0\t18.7\t394.63\t2.94\t33.4\n",
        "4\t0.06905\t0.0\t2.18\t0.0\t0.458\t7.147\t54.2\t6.0622\t3.0\t222.0\t18.7\t396.90\t5.33\t36.2\n",
        "In [17]:\n",
        "boston.isnull()    # Shows if there are missing attribute values\n",
        "Out[17]:\n",
        "CRIM\tZN\tINDUS\tCHAS\tNOX\tRM\tAGE\tDIS\tRAD\tTAX\tPTRATIO\tB\tLSTAT\tTARGET\n",
        "0\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "1\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "2\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "3\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "4\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
        "501\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "502\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "503\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "504\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "505\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\n",
        "506 rows Ã— 14 columns\n",
        "\n",
        "In [19]:\n",
        "boston.isnull().sum()      # Here it gives the sum of all 0 for false and 1 for true\n",
        "Out[19]:\n",
        "CRIM       0\n",
        "ZN         0\n",
        "INDUS      0\n",
        "CHAS       0\n",
        "NOX        0\n",
        "RM         0\n",
        "AGE        0\n",
        "DIS        0\n",
        "RAD        0\n",
        "TAX        0\n",
        "PTRATIO    0\n",
        "B          0\n",
        "LSTAT      0\n",
        "TARGET     0\n",
        "dtype: int64\n",
        "In [22]:\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X= boston.drop('TARGET', axis=1)      # Here, Axis = 1 is to drop a column and Axis =0 is to drop a row , (Drop = Delete)\n",
        "Y= boston['TARGET']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.15, random_state=5) # Here test size shows the value allocated for testing here it is 0.15 i.e, out of 100 there are 15 test values rest are training values\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)                    # Trains and test certain values\n",
        "print(Y_train.shape)                  # X contains data in Columns Y contain prediction value \n",
        "print(Y_test.shape)\n",
        "(430, 13)\n",
        "(76, 13)\n",
        "(430,)\n",
        "(76,)\n",
        "In [25]:\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.metrics import mean_squared_error\n",
        "In [26]:\n",
        "## FITTING MODEL ON THE TRAINING DATASET\n",
        "\n",
        "lin_model = LinearRegression()\n",
        "\n",
        "lin_model.fit(X_train, Y_train)\n",
        "Out[26]:\n",
        "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
        "In [30]:\n",
        "#On Training Set\n",
        "y_train_predict = lin_model.predict(X_train)\n",
        "rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
        "\n",
        "print(\"The model performing for the training set \")\n",
        "print('RMSE is {}'.format(rmse))\n",
        "print(\"\\n\")\n",
        "\n",
        "# On Testing set\n",
        "y_test_predict = lin_model.predict(X_test)\n",
        "rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
        "\n",
        "print(\"The model performing for the testing set \")\n",
        "print('RMSE is {}'.format(rmse))\n",
        "print(\"\\n\")\n",
        "The model performing for the training set \n",
        "RMSE is 4.710901797319796\n",
        "\n",
        "\n",
        "The model performing for the testing set \n",
        "RMSE is 4.687543527902972\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}